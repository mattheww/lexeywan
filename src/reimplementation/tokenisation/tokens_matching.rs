//! Applies the Pest tokenisation grammar and represents data from the resulting matches.
//!
//! See tokenise.pest in this directory for the grammar itself.
//!
//! All Pest-specific code is isolated to this module, other than the Nonterminal enumeration.

use pest::Parser;

use crate::Edition;
use crate::reimplementation::pegs::{MatchData, WrittenUp};

/// Matches as much as possible using the specified edition's tokens nonterminal.
///
/// Reports an error message if it finds a problem in lex_via_peg's model or implementation
/// (in particular, if the match attempt fails).
pub fn match_tokens(edition: Edition, input: &[char]) -> Result<TokensMatchData, String> {
    use Multiplicity::*;
    let s: String = input.iter().collect();
    let (tokens_rule, token_rule) = token_rules_for_edition(edition);
    let Ok(tokens_pairs) = TokenParser::parse(tokens_rule, &s) else {
        return Err("Pest reported no match of the tokens rule".to_owned());
    };
    let tokens_pair = extract_only_item(tokens_pairs).map_err(|m| match m {
        NoItems => "Pest reported empty response".to_owned(),
        Multiple => "Pest reported multiple top-level matches".to_owned(),
    })?;
    let matched_span = tokens_pair.as_span();
    let token_pairs = tokens_pair.into_inner();

    let mut token_kind_matches = Vec::new();
    for token_pair in token_pairs {
        if token_pair.as_rule() != token_rule {
            return Err(format!(
                "Pest matched {:?} under the tokens rule",
                token_pair.as_rule()
            ));
        }
        let token_kind_pair = extract_only_item(token_pair.into_inner()).map_err(|m| match m {
            NoItems => "Pest reported empty match of the token rule".to_owned(),
            Multiple => "Pest reported multiple tokens under the token rule".to_owned(),
        })?;
        token_kind_matches.push(TokenKindMatch::new(token_kind_pair));
    }
    Ok(TokensMatchData {
        token_kind_matches,
        consumed_entire_input: matched_span.end() == s.len(),
    })
}

/// Information about an attempt to match an edition's tokens nonterminal.
///
/// The tokens nonterminal's expression is a zero-or-more repetitions expression, so the match
/// attempt is always successful.
pub struct TokensMatchData {
    /// Each sub-match of a token-kind nonterminal
    pub token_kind_matches: Vec<TokenKindMatch>,
    /// Whether the edition's tokens nonterminal consumed all the input
    pub consumed_entire_input: bool,
}

#[derive(pest_derive::Parser)]
#[grammar = "reimplementation/tokenisation/tokenise.pest"]
/// Parser for the tokenisation grammar, generated by Pest.
struct TokenParser;

/// Enumeration of the nonterminals used in the tokenisation grammar.
///
/// This includes:
/// - the tokens nonterminals     (named like TOKENS_yyyy)
/// - the token nonterminals      (named like TOKEN_yyyy)
/// - the token-kind nonterminals (named in Title_case)
/// - subsidiary nonterminals     (named in UPPER_CASE)
///
/// Some members are nonterminals in the Pest grammar but documented as terminals in the writeup;
/// see the is_documented_as_terminal implementation below.
pub type Nonterminal = Rule;

/// Returns the Pest TOKENS and TOKEN rules to use for the specified Rust edition.
fn token_rules_for_edition(edition: Edition) -> (Rule, Rule) {
    match edition {
        Edition::E2015 => (Nonterminal::TOKENS_2015, Nonterminal::TOKEN_2015),
        Edition::E2021 => (Nonterminal::TOKENS_2021, Nonterminal::TOKEN_2021),
        Edition::E2024 => (Nonterminal::TOKENS_2024, Nonterminal::TOKEN_2024),
    }
}

/// Information from a successful match attempt of a token-kind nonterminal.
///
/// As far as the type system is concerned this could be a match of any nonterminal from the
/// tokenisation grammar, but we only use it for token-kind nonterminals.
pub type TokenKindMatch = MatchData<Nonterminal>;

impl WrittenUp for Nonterminal {
    fn is_documented_as_terminal(&self) -> bool {
        // TAB is also documented as a terminal, but it only appears in the frontmatter grammar.
        *self == Nonterminal::DOUBLEQUOTE
            || *self == Nonterminal::BACKSLASH
            || *self == Nonterminal::LF
    }
}

/// Returns the only item from an iterator, or reports an error if it didn't have exactly one item.
fn extract_only_item<T>(mut stream: impl Iterator<Item = T>) -> Result<T, Multiplicity> {
    let Some(item) = stream.next() else {
        return Err(Multiplicity::NoItems);
    };
    let None = stream.next() else {
        return Err(Multiplicity::Multiple);
    };
    Ok(item)
}

enum Multiplicity {
    NoItems,
    Multiple,
}
