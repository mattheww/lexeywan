//! Applies the Pest tokenisation grammar and represents data from the resulting matches.
//!
//! See tokenise.pest in this directory for the grammar itself.
//!
//! All Pest-specific code is isolated to this module, other than the Nonterminal enumeration.

use pest::{iterators::Pair, Parser};

use crate::char_sequences::Charseq;
use crate::Edition;

/// Matches as much as possible using the specified edition's tokens nonterminal.
///
/// Reports an error message if it finds a problem in lex_via_peg's model or implementation
/// (in particular, if the match attempt fails).
pub fn match_tokens(edition: Edition, input: &[char]) -> Result<TokensMatchData, String> {
    use Multiplicity::*;
    let s: String = input.iter().collect();
    let (tokens_rule, token_rule) = token_rules_for_edition(edition);
    let Ok(tokens_pairs) = TokenParser::parse(tokens_rule, &s) else {
        return Err("Pest reported no match of the tokens rule".to_owned());
    };
    let tokens_pair = extract_only_item(tokens_pairs).map_err(|m| match m {
        NoItems => "Pest reported empty response".to_owned(),
        Multiple => "Pest reported multiple top-level matches".to_owned(),
    })?;
    let matched_span = tokens_pair.as_span();
    let token_pairs = tokens_pair.into_inner();

    let mut token_kind_matches = Vec::new();
    for token_pair in token_pairs {
        if token_pair.as_rule() != token_rule {
            return Err(format!(
                "Pest matched {:?} under the tokens rule",
                token_pair.as_rule()
            ));
        }
        let token_kind_pair = extract_only_item(token_pair.into_inner()).map_err(|m| match m {
            NoItems => "Pest reported empty match of the token rule".to_owned(),
            Multiple => "Pest reported multiple tokens under the token rule".to_owned(),
        })?;
        token_kind_matches.push(MatchData::new(token_kind_pair));
    }
    Ok(TokensMatchData {
        token_kind_matches,
        consumed_entire_input: matched_span.end() == s.len(),
    })
}

/// Information about an attempt to match an edition's tokens nonterminal.
///
/// The tokens nonterminal's expression is a zero-or-more repetitions expression, so the match
/// attempt is always successful.
pub struct TokensMatchData {
    /// Each sub-match of a token-kind nonterminal
    pub token_kind_matches: Vec<MatchData>,
    /// Whether the edition's tokens nonterminal consumed all the input
    pub consumed_entire_input: bool,
}

#[derive(pest_derive::Parser)]
#[grammar = "lex_via_peg/tokenise.pest"]
/// Parser for the tokenisation grammar, generated by Pest.
struct TokenParser;

/// Enumeration of the nonterminals used in the tokenisation grammar.
///
/// This includes:
/// - the tokens nonterminals     (named like TOKENS_yyyy)
/// - the token nonterminals      (named like TOKEN_yyyy)
/// - the token-kind nonterminals (named in Title_case)
/// - subsidiary nonterminals     (named in UPPER_CASE)
///
/// Some members are nonterminals in the Pest grammar but documented as terminals in the writeup;
/// see [is_documented_as_terminal] below.
pub type Nonterminal = Rule;

/// Returns the Pest TOKENS and TOKEN rules to use for the specified Rust edition.
fn token_rules_for_edition(edition: Edition) -> (Rule, Rule) {
    match edition {
        Edition::E2015 => (Nonterminal::TOKENS_2015, Nonterminal::TOKEN_2015),
        Edition::E2021 => (Nonterminal::TOKENS_2021, Nonterminal::TOKEN_2021),
        Edition::E2024 => (Nonterminal::TOKENS_2024, Nonterminal::TOKEN_2024),
    }
}

/// Reports whether a nonterminal is documented as a terminal in the writeup.
fn is_documented_as_terminal(nt: Nonterminal) -> bool {
    // TAB is also documented as a terminal, but it only appears in the frontmatter grammar.
    nt == Nonterminal::DOUBLEQUOTE || nt == Nonterminal::BACKSLASH || nt == Nonterminal::LF
}

/// Information from a successful match attempt of a token-kind nonterminal.
pub struct MatchData {
    /// The token-kind nonterminal whose match is being described.
    pub token_kind_nonterminal: Nonterminal,
    /// The input characters which were consumed by the match.
    pub consumed: Charseq,
    /// The subsidiary nonterminals which participated in the match and the characters they consumed.
    /// See "elaboration" in the writeup for the order.
    /// (Strictly, this is the elaboration of the match of the nonterminal's expression, not the
    ///  elaboration of the match of the nonterminal itself.)
    /// Omits nonterminals which are documented as terminals.
    elaboration: Vec<(Nonterminal, Charseq)>,
}

impl std::fmt::Debug for MatchData {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{:?} consuming {:?}",
            self.token_kind_nonterminal, self.consumed
        )
    }
}

impl MatchData {
    /// Make a MatchData instance from the raw data provided by Pest.
    ///
    /// `pair`'s rule should be a token-kind nonterminal.
    fn new(pair: Pair<Nonterminal>) -> Self {
        Self {
            consumed: pair.as_str().into(),
            token_kind_nonterminal: pair.as_rule(),
            elaboration: pair
                .into_inner()
                .flatten()
                .filter(|sub| !is_documented_as_terminal(sub.as_rule()))
                .map(|sub| (sub.as_rule(), sub.as_str().into()))
                .collect(),
        }
    }

    /// Returns the characters consumed by the specified subsidiary nonterminal, or None if that
    /// nonterminal did not participate in this match.
    ///
    /// Reports an error if that nonterminal participated in this match more than once.
    pub fn get_checked(&self, nonterminal: Nonterminal) -> Result<Option<&Charseq>, ()> {
        let mut found = None;
        for (candidate, consumed) in self.elaboration.iter() {
            if *candidate == nonterminal {
                match found {
                    Some(_) => {
                        return Err(());
                    }
                    None => {
                        found = Some(consumed);
                    }
                }
            }
        }
        Ok(found)
    }

    /// Returns the characters consumed by the first participating match of the specified subsidiary
    /// nonterminal in this match, or None if that nonterminal did not participate in this match.
    pub fn get_first(&self, nonterminal: Nonterminal) -> Option<&Charseq> {
        for (candidate, consumed) in self.elaboration.iter() {
            if *candidate == nonterminal {
                return Some(consumed);
            }
        }
        None
    }

    /// Describes the subsidiary nonterminals making up this match, with their consumed extents.
    ///
    /// Omits nonterminals which are documented as terminals.
    pub fn describe_submatches(&self) -> impl Iterator<Item = String> + use<'_> {
        self.elaboration
            .iter()
            .map(|(rule, consumed)| format!("{rule:?} {consumed:?}"))
    }
}

/// Returns the only item from an iterator, or reports an error if it didn't have exactly one item.
fn extract_only_item<T>(mut stream: impl Iterator<Item = T>) -> Result<T, Multiplicity> {
    let Some(item) = stream.next() else {
        return Err(Multiplicity::NoItems);
    };
    let None = stream.next() else {
        return Err(Multiplicity::Multiple);
    };
    Ok(item)
}

enum Multiplicity {
    NoItems,
    Multiple,
}
