//! Applies the Pest tokenisation grammar and represents data from the resulting matches.
//!
//! See tokenise.pest in this directory for the grammar itself.
//!
//! All Pest-specific code is isolated to this module, other than the Nonterminal enumeration.

use pest::{iterators::Pair, Parser, Span};

use crate::char_sequences::Charseq;
use crate::Edition;

/// Attempts to find a single token at the start of the input by matching an edition nonterminal.
pub fn match_once(edition: Edition, input: &[char]) -> Outcome {
    use Outcome::*;
    let s: String = input.iter().collect();
    let token_rule = token_rule_for_edition(edition);
    let Ok(mut token_pairs) = TokenParser::parse(token_rule, &s) else {
        return NoMatch;
    };
    let Some(token) = token_pairs.next() else {
        return ModelError("Pest reported empty response".to_owned());
    };
    let None = token_pairs.next() else {
        return ModelError("Pest reported multiple tokens".to_owned());
    };
    let mut subs = token.into_inner();
    let Some(pair) = subs.next() else {
        return ModelError("Pest reported empty token".to_owned());
    };
    let None = subs.next() else {
        return ModelError("Pest reported multiple sub-matches for the token rule".to_owned());
    };
    Matched(MatchData::new(pair))
}

/// The result of attempting to match an edition nonterminal.
pub enum Outcome {
    /// The edition's TOKEN nonterminal matched a prefix of the input
    Matched(MatchData),

    /// The edition's TOKEN nonterminal didn't match at the start of the input
    NoMatch,

    /// The input demonstrated a problem in lex_via_peg's model or implementation.
    ///
    /// The string is a description of the problem.
    ModelError(String),
}

#[derive(pest_derive::Parser)]
#[grammar = "lex_via_peg/tokenise.pest"]
/// Parser for the tokenisation grammar, generated by Pest.
struct TokenParser;

/// Enumeration of the nonterminals used in the tokenisation grammar.
///
/// This includes:
/// - the edition nonterminals (named like TOKEN_yyyy)
/// - the token nonterminals   (named in Title_case)
/// - subsidiary nonterminals  (named in UPPER_CASE)
pub type Nonterminal = Rule;

/// Returns the TOKEN rule to use for the specified Rust edition.
fn token_rule_for_edition(edition: Edition) -> Nonterminal {
    match edition {
        Edition::E2015 => Nonterminal::TOKEN_2015,
        Edition::E2021 => Nonterminal::TOKEN_2021,
        Edition::E2024 => Nonterminal::TOKEN_2024,
    }
}

/// Information from a successful match of an edition nonterminal.
pub struct MatchData {
    /// The input characters which were consumed by the match.
    pub extent: Charseq,
    /// The token nonterminal which participated in the match.
    pub token_nonterminal: Nonterminal,
    /// The subsidiary nonterminals which participated in the match, the characters they consumed,
    /// and their spans inside the full match. Parent matches are listed before their descendents.
    participating: Vec<(Nonterminal, Charseq, SubSpan)>,
}

impl std::fmt::Debug for MatchData {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{:?} consuming {:?}",
            self.token_nonterminal, self.extent
        )
    }
}

impl MatchData {
    /// Make a MatchData instance from the raw data provided by Pest.
    ///
    /// `pair` should be the single top-level result from a successful match of an edition
    /// nonterminal.
    fn new(pair: Pair<Nonterminal>) -> Self {
        Self {
            extent: pair.as_str().into(),
            token_nonterminal: pair.as_rule(),
            participating: pair
                .into_inner()
                .flatten()
                .map(|sub| (sub.as_rule(), sub.as_str().into(), sub.as_span().into()))
                .collect(),
        }
    }

    /// Returns the characters consumed by the specified subsidiary nonterminal, or None if that
    /// nonterminal did not participate in this match.
    ///
    /// If that nonterminal participated in this match more than once:
    /// - if all the sub-matches are nested inside one "outermost" sub-match, returns that
    ///   "outermost" sub-match's characters
    /// - otherwise reports an error.
    pub fn get_checked(&self, nonterminal: Nonterminal) -> Result<Option<&Charseq>, ()> {
        let mut first_found_consumed = None;
        let mut first_found_span = None;
        for (candidate, consumed, span) in self.participating.iter() {
            if *candidate == nonterminal {
                match first_found_span {
                    Some(outermost_span) => {
                        if !span.is_inside(outermost_span) {
                            return Err(());
                        }
                    }
                    None => {
                        first_found_consumed = Some(consumed);
                        first_found_span = Some(span);
                    }
                }
            }
        }
        Ok(first_found_consumed)
    }

    /// Describes the subsidiary nonterminals making up this match, with their consumed extents.
    pub fn describe_submatches(&self) -> impl Iterator<Item = String> + use<'_> {
        self.participating
            .iter()
            .map(|(rule, consumed, _)| format!("{rule:?} {consumed:?}"))
    }
}

/// Position information for sub-matches inside MatchData.
///
/// This is used to check whether the "outermost match" principle applies when there are multiple
/// matches for a nonterminal.
struct SubSpan {
    start: usize,
    end: usize,
}

impl SubSpan {
    /// Says whether this sub-match is properly nested inside `other`.
    ///
    /// This check is meaningful only if both `SubSpan`s came from the same `MatchData`.
    fn is_inside(&self, other: &SubSpan) -> bool {
        self.start >= other.start && self.end <= other.end
    }
}

impl From<Span<'_>> for SubSpan {
    fn from(span: Span) -> Self {
        Self {
            start: span.start(),
            end: span.end(),
        }
    }
}
